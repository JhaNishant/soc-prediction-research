# Things for analysis

With 'soc_percent' as your target variable, you can perform various analyses to understand the relationship between 'soc_percent' and other features in your dataset. Here are some possible analyses:

Done! Correlation analysis: You can calculate the correlation coefficient between 'soc_percent' and other features to understand the strength and direction of the linear relationship between them. A high positive correlation indicates that as the value of one feature increases, the value of 'soc_percent' also increases, while a high negative correlation indicates that as the value of one feature increases, the value of 'soc_percent' decreases.

Done! Regression analysis: You can perform regression analysis to build a model that predicts 'soc_percent' using other features in the dataset. You can use various regression techniques like linear regression, polynomial regression, or any other regression method that suits your data.

Done! Permutation Feature importance analysis: You can analyze the importance of each feature in predicting 'soc_percent'. You can use techniques like feature importance ranking or decision tree-based methods like random forest or gradient boosting.

# Time for ML

Done! Lasso Regression

Done! Support Vector Machines (SVM)

Done! LightGBM Regression

Multilayer Perceptron (MLP)
MLPs, also known as Vanilla Neural Networks, are particularly suited for tabular data. They consist of at least three layers of nodes: an input layer, a hidden layer, and an output layer. MLPs can learn non-linear models, making them a flexible tool for many prediction tasks.
Deep Feedforward Networks (DFFNs)
DFFNs are a generalization of MLPs and are effective for tabular data. They are feedforward because information only travels forward in the network - from the input nodes, through the hidden nodes, and to the output nodes.
Transformer-Based Models
These architectures, such as TabNet and TabTransformer, rely on attention mechanisms. They have shown good performance on tabular data as they can capture complex interactions between features.
Hybrid Models
These models, such as Wide & Deep, fuse classical machine learning approaches with neural networks. They can handle high-dimensional sparse data and are designed to memorize and generalize well from the input features.
